{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/_4lvqg5s30xdvd32cgf8_mzr0000gn/T/ipykernel_77306/2907018187.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[columns_to_check]  = min_max_scaler.fit_transform(df_cleaned[columns_to_check])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo Type</th>\n",
       "      <th>Repo Name</th>\n",
       "      <th>Filename</th>\n",
       "      <th>ML TD Type</th>\n",
       "      <th>ML Pipeline Stage</th>\n",
       "      <th>NLC</th>\n",
       "      <th>CS</th>\n",
       "      <th>TFI</th>\n",
       "      <th>ANL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>AVT</th>\n",
       "      <th>AVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application</td>\n",
       "      <td>GilesStrong/lumin</td>\n",
       "      <td>lumin/nn/interpretation/features.py</td>\n",
       "      <td>MLInter</td>\n",
       "      <td>Modeling</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.054864</td>\n",
       "      <td>0.086350</td>\n",
       "      <td>0.067391</td>\n",
       "      <td>0.041439</td>\n",
       "      <td>0.073208</td>\n",
       "      <td>0.053763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Application</td>\n",
       "      <td>roscisz/TensorHive</td>\n",
       "      <td>tensorhive/controllers/reservation/update_rese...</td>\n",
       "      <td>DS Configuration</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>0.108979</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.017448</td>\n",
       "      <td>0.021286</td>\n",
       "      <td>0.043011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tool</td>\n",
       "      <td>gunthercox/ChatterBot</td>\n",
       "      <td>chatterbot/algorithms/engram.py</td>\n",
       "      <td>MLKnow</td>\n",
       "      <td>Data Pre</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>0.018539</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Application</td>\n",
       "      <td>PratikBarhate/question-classification</td>\n",
       "      <td>qc/dataprep/feature_stack.py</td>\n",
       "      <td>MDepend</td>\n",
       "      <td>Data Acq</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.021505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Application</td>\n",
       "      <td>rmalav15/Super-SloMo</td>\n",
       "      <td>data_loader.py</td>\n",
       "      <td>Data Conf</td>\n",
       "      <td>Data Acq</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.069340</td>\n",
       "      <td>0.074155</td>\n",
       "      <td>0.077014</td>\n",
       "      <td>0.279570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Application</td>\n",
       "      <td>jupyter/nbdime</td>\n",
       "      <td>nbdime/diffing/notebooks.py</td>\n",
       "      <td>Data Conf</td>\n",
       "      <td>Data Pre</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.018665</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.034331</td>\n",
       "      <td>0.021505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Application</td>\n",
       "      <td>jupyter/nbdime</td>\n",
       "      <td>nbdime/merging/generic.py</td>\n",
       "      <td>MLKnow</td>\n",
       "      <td>Data Pre</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.042180</td>\n",
       "      <td>0.154832</td>\n",
       "      <td>0.212650</td>\n",
       "      <td>0.159571</td>\n",
       "      <td>0.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Application</td>\n",
       "      <td>pyannote/pyannote-audio</td>\n",
       "      <td>pyannote/audio/pipeline/speaker_diarization.py</td>\n",
       "      <td>Data Conf</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.062783</td>\n",
       "      <td>0.074584</td>\n",
       "      <td>0.084935</td>\n",
       "      <td>0.041439</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>0.236559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Application</td>\n",
       "      <td>mne-tools/mne-python</td>\n",
       "      <td>mne/io/kit/kit.py</td>\n",
       "      <td>Data Conf</td>\n",
       "      <td>Data Pre</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.654055</td>\n",
       "      <td>0.322194</td>\n",
       "      <td>0.164667</td>\n",
       "      <td>0.309941</td>\n",
       "      <td>0.021505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Application</td>\n",
       "      <td>mne-tools/mne-python</td>\n",
       "      <td>mne/io/ctf/trans.py</td>\n",
       "      <td>MLKnow</td>\n",
       "      <td>Data Pre</td>\n",
       "      <td>0.086910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932114</td>\n",
       "      <td>0.058758</td>\n",
       "      <td>0.088332</td>\n",
       "      <td>0.085772</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Repo Type                              Repo Name  \\\n",
       "0    Application                      GilesStrong/lumin   \n",
       "1    Application                     roscisz/TensorHive   \n",
       "2           Tool                  gunthercox/ChatterBot   \n",
       "3    Application  PratikBarhate/question-classification   \n",
       "4    Application                   rmalav15/Super-SloMo   \n",
       "..           ...                                    ...   \n",
       "104  Application                         jupyter/nbdime   \n",
       "105  Application                         jupyter/nbdime   \n",
       "106  Application                pyannote/pyannote-audio   \n",
       "107  Application                   mne-tools/mne-python   \n",
       "108  Application                   mne-tools/mne-python   \n",
       "\n",
       "                                              Filename        ML TD Type  \\\n",
       "0                  lumin/nn/interpretation/features.py           MLInter   \n",
       "1    tensorhive/controllers/reservation/update_rese...  DS Configuration   \n",
       "2                      chatterbot/algorithms/engram.py            MLKnow   \n",
       "3                         qc/dataprep/feature_stack.py           MDepend   \n",
       "4                                       data_loader.py         Data Conf   \n",
       "..                                                 ...               ...   \n",
       "104                        nbdime/diffing/notebooks.py         Data Conf   \n",
       "105                          nbdime/merging/generic.py            MLKnow   \n",
       "106     pyannote/audio/pipeline/speaker_diarization.py         Data Conf   \n",
       "107                                  mne/io/kit/kit.py         Data Conf   \n",
       "108                                mne/io/ctf/trans.py            MLKnow   \n",
       "\n",
       "    ML Pipeline Stage       NLC        CS       TFI       ANL       ANC  \\\n",
       "0            Modeling  0.013948  0.054864  0.086350  0.067391  0.041439   \n",
       "1               Other  0.007511  0.031109  0.108979  0.020050  0.017448   \n",
       "2            Data Pre  0.025751  0.001697  0.009594  0.014202  0.018539   \n",
       "3            Data Acq  0.019313  0.001697  0.005793  0.006683  0.002181   \n",
       "4            Data Acq  0.347639  0.001697  0.002534  0.069340  0.074155   \n",
       "..                ...       ...       ...       ...       ...       ...   \n",
       "104          Data Pre  0.006438  0.018665  0.049783  0.043163  0.049073   \n",
       "105          Data Pre  0.442060  0.001697  0.042180  0.154832  0.212650   \n",
       "106        Evaluation  0.442060  0.062783  0.074584  0.084935  0.041439   \n",
       "107          Data Pre  0.046137  0.000566  0.654055  0.322194  0.164667   \n",
       "108          Data Pre  0.086910  1.000000  0.932114  0.058758  0.088332   \n",
       "\n",
       "          AVT       AVM  \n",
       "0    0.073208  0.053763  \n",
       "1    0.021286  0.043011  \n",
       "2    0.011013  0.032258  \n",
       "3    0.010902  0.021505  \n",
       "4    0.077014  0.279570  \n",
       "..        ...       ...  \n",
       "104  0.034331  0.021505  \n",
       "105  0.159571  0.096774  \n",
       "106  0.067184  0.236559  \n",
       "107  0.309941  0.021505  \n",
       "108  0.085772  0.064516  \n",
       "\n",
       "[108 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/dataset_with_used_metric_v2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows with null values in specified columns\n",
    "columns_to_check = [\"NLC\", \"CS\", \"TFI\", \"ANL\", \"ANC\", \"AVT\", \"AVM\"]\n",
    "df_cleaned = df.dropna(subset=columns_to_check)\n",
    "\n",
    "# Apply normalization on the specified columns\n",
    "# scaler = StandardScaler()\n",
    "# df_cleaned[columns_to_check] = scaler.fit_transform(df_cleaned[columns_to_check])\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_cleaned[columns_to_check]  = min_max_scaler.fit_transform(df_cleaned[columns_to_check])\n",
    "\n",
    "# Saving the cleaned and normalized dataset\n",
    "cleaned_file_path = '../data/dataset_with_normalized_used_metric_v2.csv'\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
